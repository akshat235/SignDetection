{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will you change the NN you choose if you were targeting real time on an embedded device ? Or if you had no time constraint during prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The widely used models for object detection can be ranked as following in terms of running time efficiency (from slowest to fastest), \n",
    "\n",
    "Sliding Window Detectors > R-CNN > Fast-RCNN > Faster-RCNN > R-FCN\n",
    "\n",
    "For real time application on an embedded device, the model should work effectively while meeting the resource constraints.\n",
    "\n",
    "**MobileNets** are one of the best models for such use cases. Mobilenets uses depth-wise separable convolutions to build light weight deep neural networks. They can be deployed with Tensforflow lite on mobile devices.\n",
    "\n",
    "I was tring **Mobilenet V2 (SSD Mobilenet)** and wanted to compare its accuracy and efficiency with R-FCN and Faster-RCNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you were given the opportunity what machine learning algorithm/method will you want to try? (please be sincere, I personally thing there is better things to do than object detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the opportunity, I want to work on adaptation of models. Tranferer Learning is getting widely used today, but models do not generalize well to new domains. I want to explore the domain adaptaion using the following two methods, **adversial alignment** and **correlation alignment**.\n",
    "Adversial alignment can help us improve application of sign detetction in different weather conditions and adapting on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does your results compare to the state of the art in sign or object detection? (You are not supposed to be as good as state of the art) What are the main differences with your approach ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently my results are not as good as state of the art results as given [here](https://www.researchgate.net/publication/321117701_A_Real-Time_Chinese_Traffic_Sign_Detection_Algorithm_Based_on_Modified_YOLOv2) but given more training time, I think it can be improved. Also, choice of model plays a major role, and that choice depends on whether we want more accuracy or faster (real-time) response.\n",
    "\n",
    "Difference in the approach: \n",
    "One problem which I see with Traffic Sign detection is the detection of Smaller Sign Images. When we apply multiple ConvNets then we tend to loose information of smaller sign images. The above paper has used multiple 1X1 convolutions in the middile layers (a modification on YOLOv2 which is similar to YOLOv3). Also, I have not changed the original image sizes but some of the papers have tried to divide the image into smaller dense images to detect the smaller signs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the challenges you expect to encounter if you had to do classification in addition to detection? For example if you had detect and classify Chinese character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do classification (classifying text characters) I will be doing the following steps (challenges specified in each point), \n",
    "    1. Aligning the characters once the bounding is detcted. Before text is read from the bounding box, we need to vertically align the text characters.\n",
    "    2. Another task/challenge is to remove out the sign from the text part.Basically removing the non-text part so that we get high OCR accuracy.\n",
    "    3. We can apply tesseract-ocr on the region obtained from 2, to get the text.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
